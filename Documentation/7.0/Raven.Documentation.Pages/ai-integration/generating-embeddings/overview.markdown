# Generating Embeddings - Overview
---

{NOTE: }

* RavenDB can serve as a vector database, see [why choose RavenDB as your vector database](../../ai-integration/vector-search/ravendb-as-vector-database#why-choose-ravendb-as-your-vector-database).

* To perform a **vector search**, your database must contain vectors embeddings:
  
  * You can store your own pre-generated embeddings in RavenDB, see [storing numerical data](../../ai-integration/vector-search/data-types-for-vector-search#numerical-data).  
  
  * Or, configure **Embeddings Generation Tasks** in the database to automatically create embeddings  
    from the content of your documents using external service providers, as explained below.

---

* In this page:
  * [Embeddings generation - overview](../../ai-integration/generating-embeddings/overview#embeddings-generation---overview)
  * [Creating an embeddings generation task](../../ai-integration/generating-embeddings/overview#embeddings-generation---overview)
  * [Monitoring the tasks](../../ai-integration/generating-embeddings/overview#monitoring-the-tasks)

{NOTE/}

---

{PANEL: Embeddings generation - overview}

{CONTENT-FRAME: }

The general flow is:

---

* **Define an Embeddings Generation Task**:  
  Specify a [connection string](../../ai-integration/connection-strings/connection-strings-overview) that defines the AI provider and model for generating embeddings.  
  Define the source content - what parts of the documents will be used to create the embeddings.  

* **Source content is processed**:  
  The task extracts the specified content from the documents.  
  The text is split according to the defined chunking method, a separate embedding will be created for each chunk.  
  If a processing script is defined, it transforms the content before sending the content to the configured AI provider.

* **Embeddings are generated by the AI provider**:  
  The provider generates embeddings and sends them back to RavenDB.  
  If quantization was defined in the task, RavenDB applies it to the embeddings before storing them.

* **Embeddings are stored in your database**:  
  * Each embedding is stored as an attachment in a [dedicated collection](../../todo..).  
  * RavenDB also maintains an [embeddings cache](), allowing reuse of embeddings for the same source content and reducing provider calls.
    Cached embeddings expire after a configurable duration.

* **Perform vector search:**  
  Once the embeddings are stored, you can perform vector searches on your document content.  
  The query search term needs to be converted to an embedding as well to compare against stored vectors.  
  If no matching embedding for the search term is found in the cache, a request is sent to the provider to generate one.

* **Continuous processing**:  
  * Embeddings generation tasks are [Ongoing Tasks](../../studio/database/tasks/ongoing-tasks/general-info) that process documents as they change.  
    Before contacting the provider after a document change, the system first checks the cache to see if a matching embedding already exists, avoiding unnecessary requests.
  * The text is sent to the providers in batches. The batch size is configurable, see the  
    [Ai.Embeddings.Generation.Task.MaxBatchSize](../../server/configuration/ai-integration-configuration#ai.embeddings.generation.task.maxbatchsize) configuration key.  
  * A failed embeddings generation task will retry after the duration set in the 
    [Ai.Embeddings.Generation.Task.RetryDelayInSec](../../server/configuration/ai-integration-configuration#ai.embeddings.generation.task.retrydelayinsec) configuration key.

{CONTENT-FRAME/}
{CONTENT-FRAME: }

* The following service providers are supported for auto-generating embeddings using tasks:

  * Azure Open AI
  * Google AI
  * Hugging Face
  * Ollama
  * OpenAI
  * Mistral AI
  * bge-micro-ve (a local embedded model within RavenDB)

{CONTENT-FRAME/}
{PANEL/}

{PANEL: Creating an embeddings generation task}

* An embeddings generation tasks can be created from:
    * The **AI Tasks view in the Studio**, where you can create, edit, and delete tasks. Learn more in [AI Tasks - list view](../../ai-integration/ai-tasks-list-view).
    * The **Client API** - see this example - todo... [embeddings generation task](../../ai-integration/generating-embeddings/embeddings-generation-task)... todo..

---

* From the Studio:  

     ![Add ai task 1](images/add-ai-task-1.png "Add AI Task")

     1. Go to the **AI Hub** menu.
     2. Open the **AI Tasks** view.
     3. Click **Add AI Task** to add a new task.

     ![Add ai task 2](images/add-ai-task-2.png "Add a new Embeddings Generation Task")

* See the complete details of the task configuration in the [Embeddings Generation Task](../../todo) article.

{PANEL/}

{PANEL: Monitoring the tasks}

* The status and state of each embeddings generation task are visible in the [AI Tasks - list view](../../ai-integration/ai-tasks-list-view).

* Task performance and activity over time can be analyzed in the _AI Tasks Stats_ view,  
  where you can track processing duration, batch sizes, and overall progress.  
  Learn more about the functionality of the stats view in the [Ongoing Tasks Stats](../../studio/database/stats/ongoing-tasks-stats/overview) article.

{PANEL/}

## Related Articles

### Vector Search

- [RavenDB as a vector database](../../ai-integration/vector-search/ravendb-as-vector-database)
- [Vector search using a static index](../../ai-integration/vector-search/vector-search-using-static-index)
- [Vector search using a dynamic query](../../ai-integration/vector-search/vector-search-using-dynamic-query)

### Embeddings Generation

- [Embeddings generation task](../../ai-integration/generating-embeddings/embeddings-generation-task)

### AI Connection Strings

- [Connection strings - overview](../../ai-integration/connection-strings/connection-strings-overview)
